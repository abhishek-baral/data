
import logging
from typing import Dict, List, Any

from google.cloud import pubsub_v1
from google.protobuf.message import Message as Message
from cavnue.messages.common.v1 import field_options_pb2
from cavnue.third_party.bq.v1 import bq_table_pb2


# remove once formally published 
def get_custom_options(message_object: Message, option_names: List[str], field_name: str = None, parse_all_fields: bool = False) -> Dict[str, Any]:
    """Get custom field options from a proto message object.
    Args:
        message_object (Message): input protobuf Message object instance
        option_names (List[str]): the list of options to look up
        field_name (str, optional): the field name in the proto to look up the options for. Defaults to None.
        parse_all_fields (bool, optional): parse all fields for the given options if True. Defaults to False.
    Returns:
        Dict[str, Any]: a dictionary mapping the value to the option
    """
    options = {}

    if not parse_all_fields and not field_name:
        raise Exception(f"One of field_option or parse_all_fields must be set")
    
    if parse_all_fields:
        for field in message_object.DESCRIPTOR.fields_by_name:
            for option in option_names:
                try:
                    value = message_object.DESCRIPTOR.fields_by_name[field].GetOptions().Extensions[getattr(field_options_pb2, option)]
                except:
                    logging.info(f"Field {field} does not have option {option} for message {message_object.__class__.__name__}. Continuing")
                    continue

                field_map = options.get(field, {})
                field_map[option] = value
                options[field] = field_map
    else:
        for option in option_names:
            try:
                options[option] = message_object.DESCRIPTOR.fields_by_name[field_name].GetOptions().Extensions[getattr(field_options_pb2, option)]
            except:
                logging.info(f"Field {field_name} does not have option {option} for message {message_object.__class__.__name__}. Continuing")
                continue

    return options


class Uploader:
    """put description here"""

    def __init__(self, cohort: str):
        self.publisher = pubsub_v1.PublisherClient()
        self.topic_path = self.publisher.topic_path(project=cohort, topic="dataflowTest") # define topic later
        self.publish_timeout = 10

    def create_hash(self, values: list) -> int:
        """generic function to hash list of values temp function, need to decide on formal hash"""
        return hash("-".join([str(v) for v in values]))

    def upload(self, proto_messages: List[Message]) -> List[int]:
        """Send an array of protos to pubsub for further processing"""
        output_messages = []
        for message in proto_messages:
            options = get_custom_options(message, ["autogenerated", "derivation"], parse_all_fields = True) # removed "row"
            for key, values in options.items():
                if values["autogenerated"]:
                    outputs = []
                    for value in values["derivation"]:
                        output = getattr(message, value)
                        outputs.append(output)
                    setattr(message, key, self.create_hash(outputs))

            # get full package path -- needs revision
            package = message.DESCRIPTOR.file.package
            file_name = f"{message.DESCRIPTOR.file.name.split('/')[-1].split('.')[0]}_pb2"
            proto_name = message.DESCRIPTOR.name

            publish_future = self.publisher.publish(
                self.topic_path,
                data=message.SerializeToString(),
                table=message.DESCRIPTOR.GetOptions().Extensions[getattr(bq_table_pb2, "bigquery_opts")].table_name,
                message=".".join([package, file_name, proto_name]),
            )
            # timeout should be a constant var
            output_messages.append(publish_future.result(timeout=self.publish_timeout))

        return output_messages
    

